{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSR2ISFGdk9l"
      },
      "source": [
        "# Проект для «Викишоп»\n",
        "\n",
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
        "\n",
        "**Цели:**\n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества F1 не меньше 0.75.\n",
        "\n",
        "Инструкция по выполнению проекта\n",
        "\n",
        "Загрузите и подготовьте данные.\n",
        "Обучите разные модели.\n",
        "Сделайте выводы.\n",
        "Для выполнения проекта применять BERT необязательно, но вы можете попробовать.\n",
        "\n",
        "# Описание данных\n",
        "\n",
        "Данные находятся в файле toxic_comments.csv. Столбец text в нём содержит текст комментария, а toxic — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PARBKTWJA8kc"
      },
      "source": [
        "# Загрузка данных\n",
        "\n",
        "https://drive.google.com/file/d/16M1xJA0tvDBT6T032BW6oYMFEspX8ETN/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCM4Q6QEg6IE",
        "outputId": "352f218d-3c16-4985-c354-4c852fa10fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: gdown: command not found\r\n"
          ]
        }
      ],
      "source": [
        "! gdown --id 16M1xJA0tvDBT6T032BW6oYMFEspX8ETN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4X90xq3_Yys",
        "outputId": "1cc4e456-a638-4d72-b0e4-6f118291b776"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet') \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppTmXa3t-eG3"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/datasets/toxic_comments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nFhSKGiE_d9Q",
        "outputId": "a4fb773f-3653-4cf0-c4db-bfab9eb37bd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH_OhXhR_gDj",
        "outputId": "bdcc4c87-9d60-4472-a61b-52c8683baa82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159571 non-null  object\n",
            " 1   toxic   159571 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX0xxMTJ_hRA",
        "outputId": "c3eecc8a-0268-4ed4-b491-5c0a5cb4e675"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk34nKvN_l0e",
        "outputId": "514ea90d-f599-40cf-92b7-face47511f81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     0\n",
              "toxic    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdshfVCp_s0Z"
      },
      "source": [
        "**Вывод**\n",
        "\n",
        "Загрузили данные, проверили и выяснили, что пропусков и дубликатов в данных нет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5XPXtSUBKoE"
      },
      "source": [
        "# Лемматизация, токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CNqEJ_B_68a"
      },
      "source": [
        "Токенизируем каждый твит, удалим стоп-слова, а также лемматизируем твиты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwqlhJXp_rk0"
      },
      "outputs": [],
      "source": [
        "corpus = data['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyOkLd1bAQA_"
      },
      "outputs": [],
      "source": [
        "def tokenize(comment):\n",
        "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "    tokens = tokenizer.tokenize(comment)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyoSoGgbASC4"
      },
      "outputs": [],
      "source": [
        "data['tokens'] = corpus.apply(lambda x: tokenize(x.lower()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njc9q0ldAT0Y"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGg3E3K9AWhp"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(tokens):\n",
        "    filtered_comment = [w for w in tokens if not w in stop_words]\n",
        "    return filtered_comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfyhQaSYAYOQ"
      },
      "outputs": [],
      "source": [
        "data['wo_stopwords'] = data['tokens'].apply(lambda x: remove_stop_words(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4GQHCFZAaAc"
      },
      "outputs": [],
      "source": [
        "def lemmatize(tokens):\n",
        "    wnl = WordNetLemmatizer()\n",
        "    lemmas = [wnl.lemmatize(word) for word in tokens]\n",
        "    return lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1NtkIBcAbjy"
      },
      "outputs": [],
      "source": [
        "data['lemmas'] = data['wo_stopwords'].apply(lambda x: lemmatize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "TbTy-aS-AdWh",
        "outputId": "8c38d158-2c2e-4968-edc0-ac88cf772cb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>tokens</th>\n",
              "      <th>wo_stopwords</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
              "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
              "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>[d, aww, he, matches, this, background, colour...</td>\n",
              "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
              "      <td>[aww, match, background, colour, seemingly, st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>[hey, man, i, m, really, not, trying, to, edit...</td>\n",
              "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
              "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[more, i, can, t, make, any, real, suggestions...</td>\n",
              "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
              "      <td>[make, real, suggestion, improvement, wondered...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
              "      <td>[sir, hero, chance, remember, page]</td>\n",
              "      <td>[sir, hero, chance, remember, page]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic  \\\n",
              "0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  D'aww! He matches this background colour I'm s...      0   \n",
              "2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [explanation, why, the, edits, made, under, my...   \n",
              "1  [d, aww, he, matches, this, background, colour...   \n",
              "2  [hey, man, i, m, really, not, trying, to, edit...   \n",
              "3  [more, i, can, t, make, any, real, suggestions...   \n",
              "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
              "\n",
              "                                        wo_stopwords  \\\n",
              "0  [explanation, edits, made, username, hardcore,...   \n",
              "1  [aww, matches, background, colour, seemingly, ...   \n",
              "2  [hey, man, really, trying, edit, war, guy, con...   \n",
              "3  [make, real, suggestions, improvement, wondere...   \n",
              "4                [sir, hero, chance, remember, page]   \n",
              "\n",
              "                                              lemmas  \n",
              "0  [explanation, edits, made, username, hardcore,...  \n",
              "1  [aww, match, background, colour, seemingly, st...  \n",
              "2  [hey, man, really, trying, edit, war, guy, con...  \n",
              "3  [make, real, suggestion, improvement, wondered...  \n",
              "4                [sir, hero, chance, remember, page]  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHbaUmJbAqNZ"
      },
      "source": [
        "**Вывод**\n",
        "\n",
        "Разделили комментарии на токены, очистили от стоп-слов и привели к леммам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Hp8T3VA0nh"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnOK33kZBWmA"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKidm7wGAkdT"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU8I38NzBgXJ"
      },
      "outputs": [],
      "source": [
        "count_tf_idf = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nucmTU6NBiGI"
      },
      "outputs": [],
      "source": [
        "target_train = train['toxic']\n",
        "features_train = train['lemmas']\n",
        "target_test = test['toxic']\n",
        "features_test = test['lemmas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9CQZH-tMC9y"
      },
      "outputs": [],
      "source": [
        "corpus_train = features_train.astype('U')\n",
        "corpus_test = features_test.astype('U')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO3NFiBDBlcz"
      },
      "outputs": [],
      "source": [
        "tf_idf = count_tf_idf.fit_transform(corpus_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfnvIBhBBnHs",
        "outputId": "dbbccbc4-0b00-4e50-9c85-092669c59ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 метрика на тренировочной выборке: 0.9710183698947744\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(random_state=12345)\n",
        "parameters = {'penalty':['l1', 'l2'],\n",
        "              'C': [10,100],\n",
        "              'solver':['liblinear'],\n",
        "              'max_iter':[100,200],\n",
        "              'class_weight':[None]}\n",
        "\n",
        "clf = GridSearchCV(lr, param_grid = parameters, scoring = 'f1', cv = 5)\n",
        "\n",
        "train_clf = clf.fit(tf_idf,target_train)\n",
        "predictions_train = clf.predict(tf_idf)\n",
        "\n",
        "f1 = f1_score(target_train, predictions_train)\n",
        "print('f1 метрика на тренировочной выборке:', f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJRXS7fMBpBN",
        "outputId": "02e0b451-fb9a-4f08-a066-0d585ff09a3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'C': 10,\n",
              " 'class_weight': None,\n",
              " 'max_iter': 100,\n",
              " 'penalty': 'l1',\n",
              " 'solver': 'liblinear'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.best_params_ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koAQgsMWMC91"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-xD6uCPCECQ"
      },
      "source": [
        "## LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS7NNR-BBq0Q",
        "outputId": "a795a3b4-482b-49e4-c2f9-6fd3c95d7f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 метрика на тренировочной выборке: 0.7884046136572419\n"
          ]
        }
      ],
      "source": [
        "lgbm = LGBMClassifier(random_state = 42)\n",
        "\n",
        "lgbm.fit(tf_idf,target_train)\n",
        "predictions_train = lgbm.predict(tf_idf)\n",
        "\n",
        "f1 = f1_score(target_train, predictions_train)\n",
        "print('f1 метрика на тренировочной выборке:', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFuvTPHNBw6b"
      },
      "source": [
        "**Вывод**\n",
        "\n",
        "Обучили две модели: Logistic Regression и LightGBM Classifier. Лучшей оказалась Logistic Regression с метрикой f1 = 0,97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9U1wBapBxAr"
      },
      "source": [
        "# Тестирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4FlTykDCYu-"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djmSDfapBtau"
      },
      "outputs": [],
      "source": [
        "tf_idf_test = count_tf_idf.transform(corpus_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Cd0Kw8CekU",
        "outputId": "44f6f7ab-76d0-478d-a3cb-842e44e4dd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 метрика логистической регрессии на тестовой выборке: 0.7788546255506609\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(random_state=12345, C = 10, class_weight = None, \n",
        "                        max_iter = 100, penalty = 'l1', solver = 'liblinear')\n",
        "lr.fit(tf_idf,target_train)\n",
        "predictions_test = lr.predict(tf_idf_test)\n",
        "f1 = f1_score(target_test, predictions_test)\n",
        "\n",
        "print('f1 метрика логистической регрессии на тестовой выборке:', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JyxBxAZCdP4"
      },
      "source": [
        "## LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqZPhPkVChG6",
        "outputId": "ee1e576c-0b30-4455-bb4e-3051bef6cdba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 метрика LightGBM на тестовой выборке: 0.757060794638583\n"
          ]
        }
      ],
      "source": [
        "predictions_test = lgbm.predict(tf_idf_test)\n",
        "f1 = f1_score(target_test, predictions_test)\n",
        "\n",
        "print('f1 метрика LightGBM на тестовой выборке:', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb7XCXNQESlg"
      },
      "source": [
        "**Вывод**\n",
        "\n",
        "Протестировали модели: Logistic Regression и LightGBM Classifier. Лучшей оказалась Logistic Regression с метрикой f1 = 0,78"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HvCu8yaCmr-"
      },
      "source": [
        "# Общий вывод\n",
        "\n",
        "В данном проекте были обучены модели, чтобы классифицировать комментарии на позитивные и негативные. Перед этим комментарии были токенизированы, очищены от стоп-слов и лемматизированы.\n",
        "\n",
        "Лучший результат f1 метрики показала модель логистической регрессии - 0.97 на тренировочной выборке и 0.78 на тестовой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXjBgEqYC4N1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 869,
        "start_time": "2022-05-08T07:23:00.594Z"
      },
      {
        "duration": 2268,
        "start_time": "2022-05-08T07:23:01.467Z"
      },
      {
        "duration": 1005,
        "start_time": "2022-05-08T07:23:03.737Z"
      },
      {
        "duration": 20,
        "start_time": "2022-05-08T07:23:04.746Z"
      },
      {
        "duration": 39,
        "start_time": "2022-05-08T07:23:04.783Z"
      },
      {
        "duration": 446,
        "start_time": "2022-05-08T07:23:04.825Z"
      },
      {
        "duration": 46,
        "start_time": "2022-05-08T07:23:05.274Z"
      },
      {
        "duration": 6,
        "start_time": "2022-05-08T07:23:05.322Z"
      },
      {
        "duration": 9,
        "start_time": "2022-05-08T07:23:05.331Z"
      },
      {
        "duration": 6299,
        "start_time": "2022-05-08T07:23:05.343Z"
      },
      {
        "duration": 6,
        "start_time": "2022-05-08T07:23:11.644Z"
      },
      {
        "duration": 29,
        "start_time": "2022-05-08T07:23:11.652Z"
      },
      {
        "duration": 2675,
        "start_time": "2022-05-08T07:23:11.684Z"
      },
      {
        "duration": 5,
        "start_time": "2022-05-08T07:23:14.361Z"
      },
      {
        "duration": 41442,
        "start_time": "2022-05-08T07:23:14.368Z"
      },
      {
        "duration": 35,
        "start_time": "2022-05-08T07:23:55.813Z"
      },
      {
        "duration": 197,
        "start_time": "2022-05-08T07:23:55.851Z"
      },
      {
        "duration": 4,
        "start_time": "2022-05-08T07:23:56.051Z"
      },
      {
        "duration": 24,
        "start_time": "2022-05-08T07:23:56.058Z"
      },
      {
        "duration": 183,
        "start_time": "2022-05-08T07:23:56.085Z"
      },
      {
        "duration": 0,
        "start_time": "2022-05-08T07:23:56.271Z"
      },
      {
        "duration": 0,
        "start_time": "2022-05-08T07:23:56.282Z"
      },
      {
        "duration": 0,
        "start_time": "2022-05-08T07:23:56.284Z"
      },
      {
        "duration": 0,
        "start_time": "2022-05-08T07:23:56.286Z"
      },
      {
        "duration": 0,
        "start_time": "2022-05-08T07:23:56.287Z"
      },
      {
        "duration": 0,
        "start_time": "2022-05-08T07:23:56.289Z"
      },
      {
        "duration": 25,
        "start_time": "2022-05-08T07:25:48.875Z"
      },
      {
        "duration": 1131,
        "start_time": "2022-05-08T07:26:15.079Z"
      },
      {
        "duration": 6378,
        "start_time": "2022-05-08T07:26:25.252Z"
      },
      {
        "duration": 886,
        "start_time": "2022-05-08T07:26:41.923Z"
      },
      {
        "duration": 2163,
        "start_time": "2022-05-08T07:26:42.812Z"
      },
      {
        "duration": 1568,
        "start_time": "2022-05-08T07:26:44.978Z"
      },
      {
        "duration": 36,
        "start_time": "2022-05-08T07:26:46.550Z"
      },
      {
        "duration": 46,
        "start_time": "2022-05-08T07:26:46.590Z"
      },
      {
        "duration": 430,
        "start_time": "2022-05-08T07:26:46.639Z"
      },
      {
        "duration": 40,
        "start_time": "2022-05-08T07:26:47.081Z"
      },
      {
        "duration": 5,
        "start_time": "2022-05-08T07:26:47.124Z"
      },
      {
        "duration": 9,
        "start_time": "2022-05-08T07:26:47.131Z"
      },
      {
        "duration": 5646,
        "start_time": "2022-05-08T07:26:47.181Z"
      },
      {
        "duration": 6,
        "start_time": "2022-05-08T07:26:52.830Z"
      },
      {
        "duration": 5,
        "start_time": "2022-05-08T07:26:52.838Z"
      },
      {
        "duration": 2319,
        "start_time": "2022-05-08T07:26:52.846Z"
      },
      {
        "duration": 5,
        "start_time": "2022-05-08T07:26:55.167Z"
      },
      {
        "duration": 49402,
        "start_time": "2022-05-08T07:26:55.183Z"
      },
      {
        "duration": 23,
        "start_time": "2022-05-08T07:27:44.588Z"
      },
      {
        "duration": 157,
        "start_time": "2022-05-08T07:27:44.614Z"
      },
      {
        "duration": 7,
        "start_time": "2022-05-08T07:27:44.774Z"
      },
      {
        "duration": 5,
        "start_time": "2022-05-08T07:27:44.784Z"
      },
      {
        "duration": 1101,
        "start_time": "2022-05-08T07:27:44.792Z"
      },
      {
        "duration": 6260,
        "start_time": "2022-05-08T07:27:45.895Z"
      },
      {
        "duration": 581734,
        "start_time": "2022-05-08T07:27:52.157Z"
      },
      {
        "duration": 7,
        "start_time": "2022-05-08T07:37:33.894Z"
      },
      {
        "duration": 844628,
        "start_time": "2022-05-08T07:37:33.903Z"
      },
      {
        "duration": 2607,
        "start_time": "2022-05-08T07:51:38.534Z"
      },
      {
        "duration": 5834,
        "start_time": "2022-05-08T07:51:41.143Z"
      },
      {
        "duration": 5540,
        "start_time": "2022-05-08T07:51:46.984Z"
      }
    ],
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}